import os
import time
import threading
import requests
from fastapi import FastAPI
from pydantic import BaseModel
from transformers import AutoTokenizer, AutoModelForCausalLM
import uvicorn
import gradio as gr

MODEL_ID = "mistralai/codestral-mamba-7b-v0.1"
API_HOST = "127.0.0.1"
API_PORT = 8000
UI_PORT = 7860
HF_TOKEN = os.getenv("HF_TOKEN")

print(f"â¬ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {MODEL_ID}")

try:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, token=HF_TOKEN)
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_ID,
        device_map="auto",
        torch_dtype="auto",
        token=HF_TOKEN
    )
    print("âœ… ãƒ­ãƒ¼ãƒ‰å®Œäº†")
except Exception as e:
    print(f"âŒ å¤±æ•—: {e}")
    exit(1)

app = FastAPI()

class GenerateRequest(BaseModel):
    prompt: str
    max_tokens: int = 128

@app.post("/generate")
def generate(req: GenerateRequest):
    try:
        inputs = tokenizer(req.prompt, return_tensors="pt").to(model.device)
        outputs = model.generate(
            **inputs,
            max_new_tokens=req.max_tokens,
            do_sample=True,
            temperature=0.7,
            top_p=0.95
        )
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        return {"response": response[len(req.prompt):]}
    except Exception as e:
        return {"error": str(e)}

def start_api():
    uvicorn.run(app, host=API_HOST, port=API_PORT, log_level="warning")

def chat(message, history):
    try:
        res = requests.post(f"http://{API_HOST}:{API_PORT}/generate", json={"prompt": message})
        return res.json().get("response", "ã‚¨ãƒ©ãƒ¼")
    except:
        return "æ¥ç¶šã‚¨ãƒ©ãƒ¼"

def start_ui():
    time.sleep(5)
    demo = gr.ChatInterface(
        fn=chat,
        title="ğŸ§  Codestral-Mamba - ãƒ­ãƒ¼ã‚«ãƒ«AIã‚³ãƒ¼ãƒ€ãƒ¼",
        description="ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ»èª¬æ˜ãƒ»ãƒ‡ãƒãƒƒã‚°æ”¯æ´",
        examples=[
            "Pythonã§CSVèª­ã¿è¾¼ã¿é–¢æ•°ã‚’æ›¸ã„ã¦",
            "Reactã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ä½œã£ã¦",
            "def add(a, b): return a - b ã«ãƒã‚°ã‚’ç›´ã—ã¦"
        ]
    )
    demo.launch(server_name="0.0.0.0", server_port=UI_PORT, share=False)

if __name__ == "__main__":
    from threading import Thread
    Thread(target=start_api, daemon=True).start()
    start_ui()